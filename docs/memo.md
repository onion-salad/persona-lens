step1でAI人格によりやりたいことをユーザーが入力する。すると、その情報を元にしてstep1担当のAIが「統計学的にユーザーの要望を完璧に満たすためには何人のAI人格が必要か（あらかじめいくつかの選択肢を用意する）」「ユーザーの要望に適したAI人格の大まかな属性情報（例えば性別や国籍、経済状況など）」「詳細情報を生成する際にどのくらい詳細に生成するか」を決定する

step2でユーザーにstep1の内容で問題ないか確認する。もし問題あれば再生成してユーザーに再度確認する（ユーザーが納得するまで何度でも確認する）。再生成の際はユーザーがチャットで追加の修正指示や要望を加えることもでき、それを元にしてAIは再生成する

step3で、step2でユーザーが承認した内容を元にして「必要な人数分のAI人格の詳細情報（ペルソナ情報）」を並列でAPIを使用して生成する（json）

step4で生成した詳細なAI人格がそれぞれstep1の内容について回答する。エクセルのような表形式でそれぞれの人格の名前とその詳細情報、回答などを1つの表に書き込んでいく。（生成が終わったものからリアルタイムで反映させていく）


step4の後は、そのままstep4の生成結果の表を画面に維持したまま以下のようにできるようにしたい。

オーケストレーター担当のAIと会話できるようにして、会話の中でまたAI人格に質問したり聞くべき内容があるとオーケストレーターが判断したら、ユーザーに「〇〇の内容に関してAI人格を呼び出し聞いてみますか？」と聞く。もしAI人格を呼び出す場合は、step3で生成したAI人格の中からオーケストレーターが「回答の質を統計学的に担保できる人数/回答に適した詳細情報を持つAI人格」をピックアップして、それぞれに質問する。
それによって得られた個々の回答はまた新たなエクセル表となって画面に追加される。画面上に表示するエクセル表は以前のものと矢印やボタンなどで切り替えられる。



キー・テイクアウェイ
Mastra 導入済み なら多エージェント実装が TypeScript だけで完結し、アーキテクチャがシンプルになる。

最初は Persona 7 名以内 + gpt-4o-mini でコストを抑え、UX で “統計的最適” を演出。

まず Estimator Agent → personaFactory → Orchestrator の最小ループを動かし、WebSocket 表ストリームで MVP 体験を作る。




今後の拡張ロードマップ（6か月想定）
Phase 1: マルチモーダル (画像/音声) Personae

Phase 2: 社内データセット接続 → “社内ベテラン仮想化”

Phase 3: 3D アバター＋音声でリアルタイムパネルディスカッション

Phase 4: パートナー API 公開 → 外部開発者が独自 Persona を販売 (Marketplace)
